The **COCO 2017** dataset is a component of the extensive **Microsoft COCO** dataset. To learn more about this dataset, you can visit its [homepage](https://cocodataset.org/#home). The creators of this dataset, in their pursuit of advancing object recognition, have placed their focus on the broader concept of scene comprehension. This vision is realized through the compilation of images depicting intricate everyday scenes where common objects naturally exist. Within the Microsoft COCO dataset, you will find photographs encompassing 91 different types of objects, all of which are easily identifiable by a four-year-old. This comprehensive dataset includes a grand total of <i>2.5 million labeled instances distributed across 328,000 images</i>. It's worth noting that in COCO 2017, specifically, you'll encounter <i>1.8 million labeled instances within 164,000 images</i>.

The dataset addresses three core research problems in scene understanding: detecting non-iconic views (or non-canonical perspectives) of objects, contextual reasoning between objects and the precise 2D localization of objects he selection of object categories is a non-trivial exercise. The categories must form a representative set of all categories, be relevant to practical applications and occur with high enough frequency to enable the collection of a large dataset.

Other important decisions are whether to include both “thing” and “stuff” categories and whether fine-grained and object-part categories should be included. “Thing” categories include objects for which individual instances may be easily labeled (*person*, *chair*, *car*) whereas “stuff” categories include materials and objects with no clear boundaries (*sky*, *street*, *grass*). Authors decided to only include “thing” categories and not “stuff” because they are primarily interested in the precise localization of object instances. Check out the [COCO-Stuff 164k](https://datasetninja.com/cocostuff164k) for details

The specificity of object categories can vary significantly. For instance, a dog could be a member of the “mammal”, “dog”, or “German shepherd” categories. To enable the practical collection of a significant number of instances per category, authors chose to limit our dataset to entry-level categories, i.e. category labels that are commonly used by humans when describing objects (dog, chair, person). It is also possible that some object categories may be parts of other object categories. For instance, a face may be part of a person. Authors anticipate the inclusion of object-part categories (face, hands, wheels) would be beneficial for many real-world applications.
